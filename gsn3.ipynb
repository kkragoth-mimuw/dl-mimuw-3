{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.0, 6.0], [8.0, 5.0], [9.0, 4.0], [8.0, 5.0], [9.0, 6.0]]\n",
      "[[7.0, 3.0], [6.0, 2.0], [5.0, 3.0], [4.0, 2.0], [3.0, 3.0]]\n",
      "[[4.0, 8.0], [5.0, 7.0], [6.0, 6.0], [7.0, 5.0], [8.0, 4.0]]\n",
      "[[6.0, 9.0], [5.0, 8.0], [6.0, 7.0], [5.0, 8.0], [4.0, 7.0]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "train_x = []\n",
    "with open('data/train_x.csv') as csvfile:\n",
    "    train_x = list(csv.reader(csvfile))\n",
    "    \n",
    "train_x = list(map(lambda x: list(map(lambda y: list(map(float, y.split('-'))), x)), train_x)) \n",
    "\n",
    "train_y = []\n",
    "with open('data/train_y.csv') as csvfile:\n",
    "    train_y = list(map(int, sum(list(csv.reader(csvfile)), [])))\n",
    "\n",
    "    \n",
    "test_x = []\n",
    "with open('data/test_x.csv') as csvfile:\n",
    "    test_x = list(csv.reader(csvfile))\n",
    "    \n",
    "test_x = list(map(lambda x: list(map(lambda y: list(map(float, y.split('-'))), x)), test_x)) \n",
    "\n",
    "test_y = []\n",
    "with open('data/test_y.csv') as csvfile:\n",
    "    test_y = list(map(int, sum(list(csv.reader(csvfile)), [])))\n",
    "    \n",
    "train_x\n",
    "train_y\n",
    "\n",
    "first_indexes_of_class = [(k, train_y.index(k)) for k in sorted(set(train_y))]\n",
    "first_indexes_of_class\n",
    "\n",
    "for (k, v) in first_indexes_of_class:\n",
    "    print(train_x[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 8.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '3-8'\n",
    "list(map(float, x.split('-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "for i in range(len(train_x[0])):\n",
    "    for (k, v) in first_indexes_of_class:\n",
    "        x = list(map(lambda x: x[0], train_x[v]))[i]\n",
    "        y = list(map(lambda x: x[1], train_x[v]))[i]\n",
    "        plt.ylim(0, 10)\n",
    "        plt.xlim(0, 10)\n",
    "        plt.scatter(x, y, c=colors[k])\n",
    "        filename='imgs/step'+str(i)+'.png'\n",
    "        plt.savefig(filename, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// convert -delay 80 *.png animated_walk.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/animated_walk.gif\" width=\"750\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_x_tensor = list(map(torch.tensor, train_x))\n",
    "train_y_tensor = torch.tensor(train_y)\n",
    "test_x_tensor = list(map(torch.tensor, test_x))\n",
    "test_y_tensor = torch.tensor(test_y)\n",
    "\n",
    "train_x_tensor[0][0].unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check\n",
      "test output\n",
      "tensor([[ 0.0546,  0.0526, -0.1477, -0.1951],\n",
      "        [-0.1265,  0.0336, -0.1225, -0.3033],\n",
      "        [-0.1539,  0.1204, -0.1984, -0.3383],\n",
      "        [-0.0570,  0.0927, -0.1143, -0.2573],\n",
      "        [-0.0825,  0.1006, -0.1194, -0.2566]], grad_fn=<AddmmBackward>)\n",
      "tensor(-0.0800, grad_fn=<NllLossBackward>)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 32)\n",
    "        self.fc2 = nn.Linear(32, output_size)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        output, _ = self.rnn(sequence.view(len(sequence), 1, -1))\n",
    "        tag_space = self.fc2(self.fc(output.view(len(sequence), -1)))\n",
    "        return tag_space\n",
    "\n",
    "    \n",
    "classifier = RNNClassifier(2, 16, 4, n_layers=2)\n",
    "\n",
    "print(\"Sanity check\")\n",
    "test_output = classifier(train_x_tensor[0])\n",
    "print('test output')\n",
    "print(test_output)\n",
    "test_loss_function = nn.NLLLoss()\n",
    "loss = test_loss_function(test_output,\n",
    "                          torch.tensor([1,1,1,1,1]))\n",
    "print(loss)\n",
    "\n",
    "output = torch.argmax(test_output[-1])\n",
    "print(output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "0 iteration, loss_for_item: 1.7063796520233154\n",
      "4000 iteration, loss_for_item: 1.4302397966384888\n",
      "8000 iteration, loss_for_item: 1.460371494293213\n",
      "Accuracy test:  0.435\n",
      "Epoch 2\n",
      "0 iteration, loss_for_item: 1.2604193687438965\n",
      "4000 iteration, loss_for_item: 1.2244865894317627\n",
      "8000 iteration, loss_for_item: 1.4706571102142334\n",
      "Accuracy test:  0.509\n",
      "Epoch 3\n",
      "0 iteration, loss_for_item: 1.1528326272964478\n",
      "4000 iteration, loss_for_item: 1.1407209634780884\n",
      "8000 iteration, loss_for_item: 1.4299938678741455\n",
      "Accuracy test:  0.541\n",
      "Epoch 4\n",
      "0 iteration, loss_for_item: 1.1102242469787598\n",
      "4000 iteration, loss_for_item: 1.1139764785766602\n",
      "8000 iteration, loss_for_item: 1.3477251529693604\n",
      "Accuracy test:  0.562\n",
      "Epoch 5\n",
      "0 iteration, loss_for_item: 1.0834349393844604\n",
      "4000 iteration, loss_for_item: 1.0935229063034058\n",
      "8000 iteration, loss_for_item: 1.2059314250946045\n",
      "Accuracy test:  0.588\n",
      "Epoch 6\n",
      "0 iteration, loss_for_item: 1.0958333015441895\n",
      "4000 iteration, loss_for_item: 1.0028369426727295\n",
      "8000 iteration, loss_for_item: 1.143469214439392\n",
      "Accuracy test:  0.61\n",
      "Epoch 7\n",
      "0 iteration, loss_for_item: 1.1821666955947876\n",
      "4000 iteration, loss_for_item: 0.9660865664482117\n",
      "8000 iteration, loss_for_item: 1.1015644073486328\n",
      "Accuracy test:  0.639\n",
      "Epoch 8\n",
      "0 iteration, loss_for_item: 1.4651416540145874\n",
      "4000 iteration, loss_for_item: 1.0275235176086426\n",
      "8000 iteration, loss_for_item: 1.0018227100372314\n",
      "Accuracy test:  0.648\n",
      "Epoch 9\n",
      "0 iteration, loss_for_item: 1.7896687984466553\n",
      "4000 iteration, loss_for_item: 1.102325439453125\n",
      "8000 iteration, loss_for_item: 0.9302510023117065\n",
      "Accuracy test:  0.652\n",
      "Accuracy reached 0.65; break\n"
     ]
    }
   ],
   "source": [
    "base_model = RNNClassifier(2, 16, 4, n_layers=2)\n",
    "base_loss_function = nn.CrossEntropyLoss()\n",
    "base_optimizer = torch.optim.SGD(base_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(30):\n",
    "    loss = 0\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for i in range(len(train_x_tensor)):\n",
    "        data_input = train_x_tensor[i]\n",
    "        target = torch.tensor([train_y[i] for _ in range(5)])\n",
    "        \n",
    "        if epoch == 0:\n",
    "            data_input = data_input[1:] if i % 2 == 0 else data_input[:-1]\n",
    "            target = torch.tensor([train_y[i] for _ in range(4)])\n",
    "        \n",
    "            \n",
    "        tag_scores = base_model(data_input)\n",
    "        base_optimizer.zero_grad()\n",
    "        \n",
    "        loss = base_loss_function(tag_scores,target)\n",
    "        \n",
    "        if i % 4000 == 0:\n",
    "            print(f\"{i} iteration, loss_for_item: {loss}\")\n",
    "            \n",
    "        loss.backward()\n",
    "        base_optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(test_x_tensor)):\n",
    "            tag_scores = base_model(test_x_tensor[i])\n",
    "            predicted = torch.argmax(tag_scores[-1]).item()\n",
    "            target = test_y[i]\n",
    "            \n",
    "            if predicted == target:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy_test = correct/len(test_x_tensor)\n",
    "                \n",
    "        print(f\"Accuracy test:  {accuracy_test}\")\n",
    "        \n",
    "        if accuracy_test > 0.65:\n",
    "            print(\"Accuracy reached 0.65; break\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(7, 6): 60, (8, 5): 49, (9, 4): 70, (9, 6): 92, (7, 3): 65, (6, 2): 4, (5, 3): 25, (4, 2): 95, (3, 3): 69, (6, 9): 13, (5, 8): 66, (6, 7): 72, (4, 7): 61, (4, 4): 99, (3, 5): 24, (3, 7): 93, (2, 8): 82, (1, 7): 64, (0, 9): 52, (1, 8): 53, (0, 7): 27, (8, 4): 5, (9, 3): 88, (8, 2): 33, (8, 3): 86, (7, 4): 15, (4, 8): 51, (5, 7): 97, (6, 6): 6, (7, 5): 90, (0, 2): 8, (1, 1): 21, (0, 0): 94, (7, 1): 31, (6, 0): 59, (5, 1): 87, (4, 0): 41, (3, 1): 2, (2, 2): 35, (5, 2): 46, (4, 3): 48, (5, 4): 7, (6, 5): 96, (3, 6): 20, (2, 7): 73, (3, 8): 40, (3, 0): 63, (4, 1): 18, (5, 0): 54, (6, 1): 34, (7, 2): 30, (9, 2): 11, (6, 3): 9, (9, 5): 1, (9, 7): 71, (8, 8): 12, (9, 9): 42, (4, 6): 26, (5, 5): 16, (6, 4): 75, (8, 6): 56, (3, 4): 89, (2, 5): 80, (1, 6): 83, (4, 9): 10, (7, 8): 91, (8, 9): 32, (9, 8): 58, (8, 7): 50, (2, 9): 62, (2, 6): 45, (2, 4): 57, (0, 3): 74, (1, 2): 28, (1, 4): 23, (0, 5): 76, (9, 1): 14, (5, 6): 78, (4, 5): 38, (8, 0): 19, (7, 7): 77, (1, 5): 85, (3, 9): 3, (5, 9): 17, (9, 0): 68, (8, 1): 84, (7, 0): 37, (2, 1): 39, (1, 0): 47, (0, 1): 81, (6, 8): 79, (7, 9): 0, (2, 0): 67, (3, 2): 44, (1, 3): 36, (2, 3): 29, (1, 9): 55, (0, 6): 43, (0, 4): 98, (0, 8): 22}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_mapping = {}\n",
    "\n",
    "def generate_random_mapping_for_entry(entry):\n",
    "    if random_mapping.get(entry) is not None:\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        suggested_entry = random.randint(0, 99)\n",
    "        \n",
    "        if suggested_entry in random_mapping.values():\n",
    "            continue\n",
    "            \n",
    "        random_mapping[entry] = suggested_entry\n",
    "        return\n",
    "    \n",
    "for sequence in train_x + test_x:\n",
    "    for node in sequence:\n",
    "        generate_random_mapping_for_entry((int(node[0]), int(node[1])))\n",
    "    \n",
    "print(random_mapping)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[60, 49, 70, 49, 92],\n",
       "        [65,  4, 25, 95, 69],\n",
       "        [13, 66, 72, 66, 61],\n",
       "        ...,\n",
       "        [90,  6, 97, 51,  3],\n",
       "        [26, 93, 45, 85, 57],\n",
       "        [67, 21, 35, 21,  8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_embedded_input = torch.tensor([list(map(lambda x: random_mapping[(x[0], x[1])], sequence)) for sequence in train_x])\n",
    "test_x_embedded_input = torch.tensor([list(map(lambda x: random_mapping[(x[0], x[1])], sequence)) for sequence in test_x])\n",
    "train_x_embedded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check\n",
      "Embeds torch.Size([5, 2])\n",
      "tensor([[-2.4630, -0.1817],\n",
      "        [ 0.6813,  1.2632],\n",
      "        [ 0.8127,  0.0718],\n",
      "        [ 0.6813,  1.2632],\n",
      "        [-1.7003,  1.0058]], grad_fn=<EmbeddingBackward>)\n",
      "test output\n",
      "tensor([[ 0.0493, -0.0240,  0.2718,  0.2054],\n",
      "        [ 0.0143,  0.0059,  0.3272,  0.2290],\n",
      "        [-0.0168,  0.0351,  0.3411,  0.2685],\n",
      "        [-0.0388,  0.0664,  0.3558,  0.2722],\n",
      "        [-0.0261,  0.0412,  0.3901,  0.2286]], grad_fn=<AddmmBackward>)\n",
      "tensor(-0.0249, grad_fn=<NllLossBackward>)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EmbeddedRNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, vocab_size=100, embedding_dim=2, n_layers=1, debug=False, fc_layers=64):\n",
    "        super(EmbeddedRNNClassifier, self).__init__()\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        embeds = self.word_embeddings(sequence)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Embeds {embeds.shape}\")\n",
    "            print(embeds)\n",
    "        output, _ = self.rnn(embeds.view(len(sequence), 1, -1))\n",
    "        tag_space = self.fc(output.view(len(sequence), -1))\n",
    "        return tag_space\n",
    "    \n",
    "    def get_word_embeddings(self):\n",
    "        return self.word_embeddings\n",
    "\n",
    "    \n",
    "classifier = EmbeddedRNNClassifier(1, 16, 4, n_layers=2, debug=True)\n",
    "\n",
    "print(\"Sanity check\")\n",
    "test_output = classifier(train_x_embedded_input[0])\n",
    "print('test output')\n",
    "print(test_output)\n",
    "test_loss_function = nn.NLLLoss()\n",
    "loss = test_loss_function(test_output,\n",
    "                          torch.tensor([1,1,1,1,1]))\n",
    "print(loss)\n",
    "\n",
    "output = torch.argmax(test_output[-1])\n",
    "print(output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Epoch 1 Accuracy test:  0.248\n",
      "Epoch 2 Accuracy test:  0.248\n",
      "Epoch 3 Accuracy test:  0.248\n",
      "Epoch 4 Accuracy test:  0.248\n",
      "Epoch 5 Accuracy test:  0.251\n",
      "Epoch 6 Accuracy test:  0.291\n",
      "Epoch 7 Accuracy test:  0.317\n",
      "Epoch 8 Accuracy test:  0.341\n",
      "Epoch 9 Accuracy test:  0.357\n",
      "Epoch 10 Accuracy test:  0.367\n",
      "Epoch 11 Accuracy test:  0.399\n",
      "Epoch 12 Accuracy test:  0.392\n",
      "Epoch 13 Accuracy test:  0.398\n",
      "Epoch 14 Accuracy test:  0.395\n",
      "Epoch 15 Accuracy test:  0.39\n",
      "Epoch 16 Accuracy test:  0.472\n",
      "Epoch 17 Accuracy test:  0.488\n",
      "Epoch 18 Accuracy test:  0.51\n",
      "Epoch 19 Accuracy test:  0.544\n",
      "Epoch 20 Accuracy test:  0.566\n",
      "Epoch 21 Accuracy test:  0.588\n",
      "Epoch 22 Accuracy test:  0.599\n",
      "Epoch 23 Accuracy test:  0.597\n",
      "Epoch 24 Accuracy test:  0.622\n",
      "Epoch 25 Accuracy test:  0.634\n",
      "Epoch 26 Accuracy test:  0.64\n",
      "Epoch 27 Accuracy test:  0.64\n",
      "Epoch 28 Accuracy test:  0.644\n",
      "Epoch 29 Accuracy test:  0.646\n",
      "Epoch 30 Accuracy test:  0.642\n",
      "Epoch 31 Accuracy test:  0.657\n",
      "Accuracy reached 0.65; break\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = EmbeddedRNNClassifier(1, 64, 4, embedding_dim=2, n_layers=4)\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "\n",
    "points_to_embed = [(0, 1), (1, 0), (6, 8), (7, 9)]\n",
    "embeddings = {}\n",
    "\n",
    "for point in points_to_embed:\n",
    "    embeddings[point] = {\"x\": [], \"y\":[]}\n",
    "\n",
    "    \n",
    "print(\"Running...\")\n",
    "\n",
    "train_x_embedded_input_tensor = train_x_embedded_input.to(device)\n",
    "test_x_embedded_input_tensor = test_x_embedded_input.to(device)\n",
    "train_y_tensor = torch.tensor([[train_y[i] for _ in range(5)] for i in range(len(train_y))]).to(device)\n",
    "test_y_tensor = torch.tensor([[train_y[i] for _ in range(5)] for i in range(len(test_y))]).to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(len(train_x_embedded_input_tensor)):\n",
    "        data_input = train_x_embedded_input_tensor[i]\n",
    "        target = train_y_tensor[i]\n",
    "        \n",
    "        tag_scores = model(data_input)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = loss_function(tag_scores,target) \n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "\n",
    "        for i in range(len(test_x_embedded_input_tensor)):\n",
    "            data_input = test_x_embedded_input_tensor[i]\n",
    "            tag_scores = model(data_input)\n",
    "            predicted = torch.argmax(tag_scores[-1]).item()\n",
    "            target = test_y[i]\n",
    "            \n",
    "            if predicted == target:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy_test = correct/len(test_x_embedded_input)\n",
    "                \n",
    "        print(f\"Epoch {epoch+1} Accuracy test:  {accuracy_test}\")\n",
    "        \n",
    "        for point in points_to_embed:\n",
    "            point_embedding = model.get_word_embeddings()(torch.tensor(random_mapping[point]).to(device))    \n",
    "            embeddings[point][\"x\"].append(point_embedding[0].to('cpu').item())\n",
    "            embeddings[point][\"y\"].append(point_embedding[1].to('cpu').item())\n",
    "\n",
    "        if accuracy_test >= 0.65:\n",
    "            print(\"Accuracy reached 0.65; break\")\n",
    "            break\n",
    "            \n",
    "    scheduler.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_length = len(embeddings[points_to_embed[0]][\"x\"])\n",
    "\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "\n",
    "for e in range(epochs_length):\n",
    "    for i,k in enumerate(embeddings.keys()):\n",
    "        x = [embeddings[k][\"x\"][e]]\n",
    "        y = [embeddings[k][\"y\"][e]]\n",
    "        plt.ylim(-3, 3)\n",
    "        plt.xlim(-3, 3)\n",
    "        plt.scatter(x, y, c=colors[i])\n",
    "        epoch_name = str(e) if e >= 10 else \"0\" + str(e)\n",
    "        filename='imgs2/epoch'+epoch_name+'.png'\n",
    "        plt.savefig(filename, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs2/animated_embed.gif\" width=\"750\" align=\"center\">\n",
    "\n",
    "red - (0,1)\n",
    "green - (1,0)\n",
    "blue - (6,8)\n",
    "yellow - (7,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
